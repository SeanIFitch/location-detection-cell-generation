{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfdbfc5-1024-42fd-8ff7-cfa74df6092e",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from utils import absolute_path\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from position_fix_utils import filter_by_date, smooth_trajectory, distance_between_points\n",
    "from gb_spm import characteristic_indices, significant_place_mining\n",
    "import webbrowser\n",
    "from LabelPlot import LabelPlot\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    CircleMarker,\n",
    "    Polyline,\n",
    "    Popup,\n",
    "    Marker,\n",
    ")\n",
    "import ipywidgets as widgets\n",
    "from MapPlot import MapPlot\n",
    "from scipy import stats\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d993c723-d8fa-4f62-b0d3-b032eebc0a39",
   "metadata": {},
   "source": [
    "# load data from csv\n",
    "\n",
    "position_fix_dtype = np.dtype([\n",
    "    ('lat', np.float64),\n",
    "    ('lon', np.float64),\n",
    "    ('time', np.float64),\n",
    "    ('altitude', np.float64),\n",
    "    ('bearing', np.float64),\n",
    "    ('speed', np.float64),\n",
    "    ('accuracy', np.float64),\n",
    "    ('vertical_accuracy', np.float64),\n",
    "    ('bearing_accuracy', np.float64),\n",
    "    ('speed_accuracy', np.float64),\n",
    "])\n",
    "\n",
    "\n",
    "def position_fix_from_csv(file_path, remove_duplicates=True):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        prior = None\n",
    "        for row in reader:\n",
    "            point = (\n",
    "                float(row['latitude']),\n",
    "                float(row['longitude']),\n",
    "                float(row['create_time_epoch']),\n",
    "                float(row['altitude']),\n",
    "                float(row['bearing']),\n",
    "                float(row['speed']),\n",
    "                float(row['accuracy']),\n",
    "                float(row['vertical_accuracy']),\n",
    "                float(row['bearing_accuracy']),\n",
    "                float(row['speed_accuracy']),\n",
    "            )\n",
    "            if remove_duplicates:\n",
    "                if prior is not None and prior == point:\n",
    "                    continue\n",
    "                else:\n",
    "                    prior = point\n",
    "            data.append(point)\n",
    "    return np.array(data, dtype=position_fix_dtype)\n",
    "\n",
    "\n",
    "data_path = absolute_path(\"andrew-device-locations-all.csv\")\n",
    "location_data = position_fix_from_csv(data_path)\n",
    "print('done')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda95c64-7c1e-4030-af1e-0abf3fb61630",
   "metadata": {},
   "source": [
    "# Get all labeled date data\n",
    "def get_data(date):\n",
    "    day_data = filter_by_date(location_data, date)\n",
    "    \n",
    "    file_path = date.strftime(\"%Y-%m-%d\") + \"-labels.csv\"\n",
    "    try:\n",
    "        labels = np.loadtxt(file_path, delimiter=',').astype(int)\n",
    "        assert len(day_data) == len(labels)\n",
    "    except:\n",
    "        print(f\"Error: {date.strftime('%Y-%m-%d')} not labeled.\")\n",
    "        labels = None\n",
    "    \n",
    "    return day_data, labels\n",
    "\n",
    "dates = [\n",
    "    datetime(2024, 4, 19), \n",
    "    datetime(2024, 4, 20),\n",
    "    datetime(2024, 5, 11),\n",
    "]\n",
    "X = []\n",
    "y = []\n",
    "for date in dates:\n",
    "    Xi, yi = get_data(date)\n",
    "    X.append(Xi)\n",
    "    y.append(yi)\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)\n",
    "print(\"done\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68dbafe4-f470-482b-a9e0-1ee5e5f12351",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "\n",
    "# Include prior and posterior lengths in X\n",
    "def extract_features(X, y, mode='valid', r_index=1): \n",
    "    fields = ['bearing', 'speed', 'accuracy', 'vertical_accuracy', 'bearing_accuracy', 'speed_accuracy'] # 'altitude'\n",
    "    X_features = np.column_stack([X[field] for field in fields])\n",
    "    if r_index <= 0:\n",
    "        return X_features, y\n",
    "\n",
    "    distance = distance_between_points(X, unit='m')\n",
    "    distance = distance.reshape((len(distance), 1))\n",
    "    time_diff = np.diff(X['time'])    \n",
    "    \n",
    "    if mode == 'valid':\n",
    "        X_features = [X_features[r_index:-r_index]]\n",
    "        n = len(X) - 2 * r_index\n",
    "        X_features += [distance[i:i+n] for i in range(2 * r_index)]\n",
    "        X_features += [time_diff[i:i+n] for i in range(2 * r_index)]\n",
    "        X_features = np.column_stack(X_features)\n",
    "        y_correct_length = y[r_index:-r_index] if y is not None else y\n",
    "    elif mode == 'edge':\n",
    "        raise NotImplementedError(\"Edge mode is not implemented.\")\n",
    "    else:\n",
    "        raise ValueError(f\"{mode} mode not supported.\")\n",
    "\n",
    "    return X_features, y_correct_length\n",
    "\n",
    "r_index=4\n",
    "X_features, y_length = extract_features(X, y, 'valid', r_index)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_length, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data. Avoid data snooping.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(\"done\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ff038ea-9f01-481e-82f4-531db94147d5",
   "metadata": {},
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  \n",
    "    Dense(128, activation='relu'),     \n",
    "    BatchNormalization(),              \n",
    "    Dense(128, activation='relu'),     \n",
    "    Dropout(0.2),                      \n",
    "    Dense(1, activation='sigmoid')     \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For unbalanced classes\n",
    "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "class_weights = {cls: len(y_train) / (len(unique_classes) * count) for cls, count in zip(unique_classes, class_counts)}\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=4000, class_weight=class_weights)\n",
    "pass\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe4ce6a-99b5-4082-8761-3e1ca475e8a8",
   "metadata": {},
   "source": [
    "def show_confusion_matrix(model, X, y):\n",
    "    # Predict classes for the test set\n",
    "    y_pred = model.predict(X)\n",
    "    f1 = f1_score(y, y_pred.round())\n",
    "    print(\"F1 score:\", f1)\n",
    "    \n",
    "    # Convert predicted probabilities to class labels\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred_classes)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "show_confusion_matrix(model, X_test, y_test)\n",
    "show_confusion_matrix(model, X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65c82434-e998-4717-a8ae-77fcaa0699ca",
   "metadata": {},
   "source": [
    "# Display results for a given day\n",
    "date = datetime(2024, 4, 18)\n",
    "plot_data, real_labels = get_data(date)\n",
    "\n",
    "# gb-spm to find significant places\n",
    "def gb_spm(data):\n",
    "    smoothed = smooth_trajectory(data, s=5e-11 * len(data), weight='inverse')\n",
    "    cp_indices = characteristic_indices(smoothed, 4, 1)  # [45:47]\n",
    "    characteristic_points = data[cp_indices]\n",
    "    significant_places = significant_place_mining(smoothed, cp_indices, 3, 0.25, 120, 60)\n",
    "\n",
    "    return significant_places\n",
    "\n",
    "features, labels = extract_features(plot_data, real_labels, 'valid', r_index)\n",
    "features_scaled = scaler.transform(features)\n",
    "pred_labels = model.predict(features_scaled)\n",
    "\n",
    "label_plot = LabelPlot()\n",
    "label_plot.add_curve(plot_data)\n",
    "label_plot.add_stop_regions(gb_spm(plot_data), markers=True, color='magenta', draggable=True)\n",
    "label_plot.add_points_clickable(plot_data[r_index:-r_index], labels=pred_labels)\n",
    "label_plot"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a9ea4-f44c-474f-97d7-f5c0e46bac92",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
